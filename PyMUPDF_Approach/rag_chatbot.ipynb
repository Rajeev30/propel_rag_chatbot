{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, pytesseract\n",
    "import spacy, csv, mimetypes\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()                           # expects .env in the repo root\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_ENV     = os.getenv(\"PINECONE_ENV\")  # e.g. \"gcp-starter\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPERATION AND\n",
      "MAINTENANCE MANUAL\n",
      "Bench Lathe\n",
      "Art. T999/230V ‚Äì T999/230V3A\n",
      "Art. T999/400V - T999/400V3A\n",
      "TRANSLATION OF THE ORIGINAL INSTRUCTIONS\n",
      "fervi.com\n",
      "\n",
      "MACHINES AND\n",
      "ACCESSORIES\n",
      "Page 2 of 84\n",
      "PREFACE\n",
      "Please ensure you have read this manual before operation\n",
      "TRANSLATION OF THE ORIGINAL INSTRUCTIONS\n",
      "It is compulsory to read this instruction manual before starting operation. The guarantee of\n",
      "smooth operation and full performance of the machine is highly dependent on the application\n",
      "of all the instructions contained in this manual.\n",
      "Operator qualifications\n",
      "The workers responsible for the use of this machine must have all the necessary\n",
      "information and instruction and should be given adequate training in relation to safety\n",
      "regarding:\n",
      "a)\n",
      "Conditions of use for the equipment;\n",
      "b)\n",
      "Foreseeable abnormal situations, pursuant to Article 73 of Legislative Decree\n",
      "81/08.\n",
      "We guarantee the Machine complies with the specifications and technical instructions\n",
      "described in the Manual on the date of issuance an\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "def load_pdf(path: Path) -> str:\n",
    "    doc = fitz.open(path)\n",
    "    text = []\n",
    "    for page in doc:\n",
    "        text.append(page.get_text(\"text\"))\n",
    "    return \"\\n\".join(text)\n",
    "\n",
    "raw_text = load_pdf(Path(\"/Users/rajeev/Downloads/doc2.pdf\"))\n",
    "print(raw_text[:1000])   # sanity‚Äëcheck first 1‚ÄØ000 chars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, base64\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import fitz                         # PyMuPDF 2.0+\n",
    "import tabula                       # needs Java;  pip install tabula-py jpype1\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_directories(base_dir: str = \"data\"):\n",
    "#     for leaf in [\"images\", \"text\", \"tables\", \"page_images\"]:\n",
    "#         os.makedirs(Path(base_dir) / leaf, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_tables(filepath: str, doc, page_num: int, base_dir: str, items: list):\n",
    "#     \"\"\"Extract all tables on a page with Tabula ‚Üí save as txt.\"\"\"\n",
    "#     try:\n",
    "#         tables = tabula.read_pdf(filepath, pages=page_num + 1, multiple_tables=True)\n",
    "#         if not tables:\n",
    "#             return\n",
    "#         for t_idx, df in enumerate(tables):\n",
    "#             table_text = \"\\n\".join([\" | \".join(map(str, row)) for row in df.values])\n",
    "#             fname = Path(base_dir) / \"tables\" / f\"{Path(filepath).stem}_table_{page_num}_{t_idx}.txt\"\n",
    "#             fname.write_text(table_text, encoding=\"utf-8\")\n",
    "#             items.append({\"page\": page_num, \"type\": \"table\", \"text\": table_text, \"path\": str(fname)})\n",
    "#     except Exception as e:\n",
    "#         print(f\"[warn] page {page_num}: table extract failed ‚ûú {e}\")\n",
    "\n",
    "# def process_text_chunks(text: str, splitter, page_num: int, base_dir: str, filepath: str, items: list):\n",
    "#     for i, chunk in enumerate(splitter.split_text(text)):\n",
    "#         fname = Path(base_dir) / \"text\" / f\"{Path(filepath).stem}_text_{page_num}_{i}.txt\"\n",
    "#         fname.write_text(chunk, encoding=\"utf-8\")\n",
    "#         items.append({\"page\": page_num, \"type\": \"text\", \"text\": chunk, \"path\": str(fname)})\n",
    "\n",
    "# def process_images(doc, page, page_num: int, base_dir: str, filepath: str, items: list):\n",
    "#     for idx, img in enumerate(page.get_images(full=True)):\n",
    "#         xref = img[0]\n",
    "#         pix = fitz.Pixmap(doc, xref)\n",
    "#         # handle CMYK ‚Üí RGB\n",
    "#         if pix.alpha or pix.colorspace.n > 3:\n",
    "#             pix = fitz.Pixmap(fitz.csRGB, pix)\n",
    "#         fname = Path(base_dir) / \"images\" / f\"{Path(filepath).stem}_image_{page_num}_{idx}_{xref}.png\"\n",
    "#         pix.save(fname)\n",
    "#         items.append({\n",
    "#             \"page\": page_num, \"type\": \"image\", \"path\": str(fname),\n",
    "#             \"image\": base64.b64encode(fname.read_bytes()).decode(\"utf-8\")\n",
    "#         })\n",
    "\n",
    "# def process_page_image(page, page_num: int, base_dir: str, items: list):\n",
    "#     pix = page.get_pixmap(matrix=fitz.Matrix(2,2))   # 2√ó for crispness\n",
    "#     fname = Path(base_dir) / \"page_images\" / f\"page_{page_num:03d}.png\"\n",
    "#     pix.save(fname)\n",
    "#     items.append({\n",
    "#         \"page\": page_num, \"type\": \"page\", \"path\": str(fname),\n",
    "#         \"image\": base64.b64encode(fname.read_bytes()).decode(\"utf-8\")\n",
    "#     })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDF pages: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 84/84 [00:29<00:00,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ  finished ‚Äì extracted 750 items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# filepath = \"/Users/rajeev/Downloads/doc2.pdf\"          # ‚Üê update if needed\n",
    "# base_dir = \"data\"              # root output folder\n",
    "\n",
    "# create_directories(base_dir)\n",
    "# splitter = RecursiveCharacterTextSplitter(\n",
    "#     chunk_size=700, chunk_overlap=200, length_function=len\n",
    "# )\n",
    "\n",
    "# items = []\n",
    "\n",
    "# doc = fitz.open(filepath)\n",
    "# for page_num in tqdm(range(len(doc)), desc=\"Processing PDF pages\"):\n",
    "#     page = doc[page_num]\n",
    "#     text = page.get_text(\"text\")\n",
    "\n",
    "#     process_tables(filepath, doc, page_num, base_dir, items)\n",
    "#     process_text_chunks(text, splitter, page_num, base_dir, filepath, items)\n",
    "#     process_images(doc, page, page_num, base_dir, filepath, items)\n",
    "#     process_page_image(page, page_num, base_dir, items)\n",
    "\n",
    "# print(f\"‚úÖ  finished ‚Äì extracted {len(items)} items\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # First text chunk ‚Äì preview 200 chars\n",
    "# first_text = next(obj for obj in items if obj[\"type\"] == \"text\")\n",
    "# print(first_text[\"text\"][:200])\n",
    "\n",
    "# # First table ‚Äì preview 200 chars\n",
    "# first_table = next(obj for obj in items if obj[\"type\"] == \"table\")\n",
    "# print(first_table[\"text\"][:200])\n",
    "\n",
    "# # First image ‚Äì show path (or the base64 string length, etc.)\n",
    "# first_img = next(obj for obj in items if obj[\"type\"] == \"image\")\n",
    "# print(first_img[\"path\"])\n",
    "# # print(len(first_img[\"image\"]))   # if you want to confirm it‚Äôs base64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pdfplumber jpype1 tabula-py pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os, base64, json, fitz, pdfplumber\n",
    "from tqdm import tqdm\n",
    "import tabula\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "PDF_PATH  = Path(\"/Users/rajeev/Downloads/doc2.pdf\")\n",
    "BASE_DIR  = Path(\"data\")\n",
    "DIAGRAM_THRESHOLD = 0.60   # % of page area to be considered full-page diagram\n",
    "LOGO_THRESHOLD    = 0.10   # % of page area under which we skip as logo/ornament\n",
    "TEXT_EMPTY_LIMIT   = 100   # page is ‚Äúempty‚Äù if ‚â§ 100 chars\n",
    "NEIGHBOR_MIN_CHARS = 200   # char count to decide page is \"mostly image\"\n",
    "PIXMAP_ZOOM       = 3      # render factor for full page images\n",
    "# ----------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1 ¬∑ utils ------------------------------------------------------\n",
    "def ensure_dirs():\n",
    "    for sub in [\"images\", \"text\", \"tables\", \"page_images\"]:\n",
    "        (BASE_DIR / sub).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_txt(fname: Path, txt: str):\n",
    "    fname.write_text(txt, encoding=\"utf-8\")\n",
    "\n",
    "def save_pixmap(pix: fitz.Pixmap, fname: Path):\n",
    "    if pix.alpha or pix.colorspace.n > 3:\n",
    "        pix = fitz.Pixmap(fitz.csRGB, pix)\n",
    "    pix.save(fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2 ¬∑ caption cache stub ----------------------------------------\n",
    "CAPTION_CACHE_FILE = \"captions_cache.json\"\n",
    "if Path(CAPTION_CACHE_FILE).exists():\n",
    "    CAPTION_CACHE = json.loads(Path(CAPTION_CACHE_FILE).read_text())\n",
    "else:\n",
    "    CAPTION_CACHE = {}\n",
    "\n",
    "def caption_image_cached(path: Path) -> str:\n",
    "    key = str(path.resolve())\n",
    "    if key in CAPTION_CACHE:\n",
    "        return CAPTION_CACHE[key]\n",
    "    # --- call your GPT-4o vision captioner here ---\n",
    "    caption = \"[CAPTION]\"  # placeholder\n",
    "    CAPTION_CACHE[key] = caption\n",
    "    Path(CAPTION_CACHE_FILE).write_text(json.dumps(CAPTION_CACHE, indent=2))\n",
    "    return caption\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import imagehash\n",
    "\n",
    "# Global trackers\n",
    "HASH_COUNTS = {}\n",
    "SKIP_HASHES = set()\n",
    "\n",
    "def pixmap_to_pil(pix: fitz.Pixmap) -> Image.Image:\n",
    "    \"\"\"Convert PyMuPDF pixmap to PIL Image, with fallback for broken samples\"\"\"\n",
    "    try:\n",
    "        # Convert via bytes safely\n",
    "        mode = \"RGB\" if pix.n < 5 else \"RGBA\"\n",
    "        img_bytes = pix.tobytes(output=\"ppm\")  # robust fallback\n",
    "        return Image.open(BytesIO(img_bytes)).convert(mode)\n",
    "    except Exception as e:\n",
    "        print(f\"[warn] pixmap_to_pil failed: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def should_skip_pil_image(pil_img: Image.Image, min_repeat: int = 3) -> bool:\n",
    "    \"\"\"Decide whether to skip an image based on perceptual hash frequency\"\"\"\n",
    "    img_hash = str(imagehash.phash(pil_img))\n",
    "    if img_hash in SKIP_HASHES:\n",
    "        return True\n",
    "    HASH_COUNTS[img_hash] = HASH_COUNTS.get(img_hash, 0) + 1\n",
    "    if HASH_COUNTS[img_hash] >= min_repeat:\n",
    "        SKIP_HASHES.add(img_hash)\n",
    "        return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_headings(words):\n",
    "    \"\"\"Heuristic: return candidate headings by largest font sizes (based on height).\"\"\"\n",
    "    if not words: \n",
    "        return []\n",
    "    # Estimate font size from height\n",
    "    for w in words:\n",
    "        w[\"size\"] = round(w[\"bottom\"] - w[\"top\"], 2)\n",
    "\n",
    "    # Pick largest 2-3 sizes as likely headings\n",
    "    sizes = sorted({w[\"size\"] for w in words}, reverse=True)[:3]\n",
    "    headings = [w for w in words if w[\"size\"] in sizes and w[\"text\"].strip()]\n",
    "\n",
    "    # Group into lines\n",
    "    result = []\n",
    "    line = \"\"\n",
    "    y_prev = None\n",
    "    for w in headings:\n",
    "        if y_prev is None or abs(w[\"top\"] - y_prev) < 2:\n",
    "            line += \" \" + w[\"text\"]\n",
    "        else:\n",
    "            result.append(line.strip())\n",
    "            line = w[\"text\"]\n",
    "        y_prev = w[\"top\"]\n",
    "    if line.strip(): \n",
    "        result.append(line.strip())\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "WARNING_TAGS = (\"WARNING\", \"CAUTION\", \"DANGER\", \"NOTE\", \"STEP\")\n",
    "def tag_special_chunks(txt:str)->str:\n",
    "    for tag in WARNING_TAGS:\n",
    "        if txt.upper().startswith(tag):\n",
    "            return f\"[{tag}] {txt}\"\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 ¬∑ main extractor --------------------------------------------\n",
    "def extract_pdf(pdf_path: Path):\n",
    "    ensure_dirs()\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=700, chunk_overlap=200)\n",
    "\n",
    "    items = []\n",
    "    doc   = fitz.open(pdf_path)\n",
    "\n",
    "    for page_idx in tqdm(range(len(doc)), desc=\"Processing pages\"):\n",
    "        page = doc[page_idx]\n",
    "        # Default section heading for page\n",
    "        current_h = \"\"\n",
    "        try:\n",
    "            with pdfplumber.open(pdf_path) as plumber_pdf:\n",
    "                plumber_page = plumber_pdf.pages[page_idx]\n",
    "                pl_words = plumber_page.extract_words()\n",
    "                headings = extract_headings(pl_words)\n",
    "                current_h = headings[0] if headings else \"\"\n",
    "        except Exception as e:\n",
    "            print(f\"[warn] heading extraction failed on page {page_idx}: {e}\")\n",
    "\n",
    "        raw_text = page.get_text(\"text\", sort=True).strip()\n",
    "        if len(raw_text) < 20:            # likely scanned text\n",
    "            ocr_img = page.get_pixmap(matrix=fitz.Matrix(2,2))\n",
    "            ocr_txt = pytesseract.image_to_string(Image.open(BytesIO(ocr_img.tobytes()))).strip()\n",
    "            if len(ocr_txt) > 20:\n",
    "                raw_text = ocr_txt\n",
    "\n",
    "        # ---------- Table extraction ----------\n",
    "        # ---------- Table extraction with fallback ----------\n",
    "        import csv\n",
    "\n",
    "        # ---------- Table extraction with fallback and cleanup ----------\n",
    "        tables = []\n",
    "\n",
    "        # Try Tabula (best for ruled tables)\n",
    "        try:\n",
    "            tables = tabula.read_pdf(str(pdf_path), pages=page_idx + 1, multiple_tables=True)\n",
    "        except Exception as e:\n",
    "            print(f\"[warn] tabula failed on page {page_idx}: {e}\")\n",
    "\n",
    "        # Fallback to pdfplumber\n",
    "        if not tables:\n",
    "            try:\n",
    "                with pdfplumber.open(pdf_path) as plumber_pdf:\n",
    "                    plumber_page = plumber_pdf.pages[page_idx]\n",
    "                    extracted = plumber_page.extract_tables()\n",
    "                    for t in extracted:\n",
    "                        if any(cell for row in t for cell in row if cell and cell.strip()):\n",
    "                            tables.append(t)\n",
    "            except Exception as e:\n",
    "                print(f\"[warn] pdfplumber failed on page {page_idx}: {e}\")\n",
    "\n",
    "        # Process extracted tables\n",
    "        for t_idx, table in enumerate(tables):\n",
    "            cleaned_rows = []\n",
    "\n",
    "            # Tabula: pandas DataFrame\n",
    "            if hasattr(table, \"values\"):\n",
    "                rows = table.values.tolist()\n",
    "            else:\n",
    "                rows = table  # pdfplumber: list of lists\n",
    "\n",
    "            # Clean: strip whitespace, flatten \\n, fill empty with \"\"\n",
    "            for row in rows:\n",
    "                row = [str(cell).strip().replace(\"\\n\", \" \") if cell else \"\" for cell in row]\n",
    "                if any(cell for cell in row):  # skip empty rows\n",
    "                    cleaned_rows.append(row)\n",
    "\n",
    "            # --- Reconstruct multiline rows ---\n",
    "            reconstructed_rows = []\n",
    "            current_row = None\n",
    "\n",
    "            for row in cleaned_rows:\n",
    "                if row[0].strip():  # new row\n",
    "                    if current_row:\n",
    "                        reconstructed_rows.append(current_row)\n",
    "                    current_row = row\n",
    "                else:  # continuation of previous row\n",
    "                    if current_row:\n",
    "                        for i in range(len(row)):\n",
    "                            if row[i].strip():\n",
    "                                current_row[i] += \" \" + row[i]\n",
    "\n",
    "            if current_row:\n",
    "                reconstructed_rows.append(current_row)\n",
    "\n",
    "            # Convert to clean text for embedding\n",
    "            table_text = \"\\n\".join([\" | \".join(row) for row in reconstructed_rows])\n",
    "\n",
    "            # Save .txt for RAG\n",
    "            f = BASE_DIR / \"tables\" / f\"{pdf_path.stem}_table_{page_idx}_{t_idx}.txt\"\n",
    "            save_txt(f, table_text)\n",
    "\n",
    "            # Save .csv for inspection\n",
    "            csv_path = f.with_suffix(\".csv\")\n",
    "            with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "                writer = csv.writer(csvfile)\n",
    "                writer.writerows(reconstructed_rows)\n",
    "\n",
    "            # Append to items for embedding\n",
    "            items.append({\n",
    "                \"page\": page_idx,\n",
    "                \"type\": \"table\",\n",
    "                \"text\": table_text,\n",
    "                \"path\": str(f)\n",
    "            })\n",
    "\n",
    "            m = re.search(r\"(Table\\s+\\d+\\s*[\\‚Äì\\-‚Äî]\\s*[^\\n]{5,80})\", raw_text)\n",
    "            if m:\n",
    "                items[-1][\"caption_title\"] = m.group(1).strip()\n",
    "\n",
    "        # ---------- Text chunking ----------\n",
    "        if raw_text:\n",
    "            for i, chunk in enumerate(splitter.split_text(raw_text)):\n",
    "                f = BASE_DIR / \"text\" / f\"{pdf_path.stem}_text_{page_idx}_{i}.txt\"\n",
    "                save_txt(f, chunk)\n",
    "                items.append({\n",
    "                    \"page\": page_idx,\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": chunk,\n",
    "                    \"section\": current_h,           # ‚ñ∂Ô∏è  add detected heading\n",
    "                    \"path\": str(f)\n",
    "                })\n",
    "\n",
    "        # ---------- Image logic ----------\n",
    "        page_bbox = page.rect\n",
    "        page_area = page_bbox.width * page_bbox.height\n",
    "        full_page_diagram = False\n",
    "\n",
    "        with pdfplumber.open(pdf_path) as plumber_pdf:\n",
    "            plumber_page = plumber_pdf.pages[page_idx]\n",
    "            imgs = plumber_page.images  # gives bbox coords\n",
    "            print(f\"[Page {page_idx}] {len(imgs)} images found\")\n",
    "            for img in imgs:\n",
    "                img_area = img[\"width\"] * img[\"height\"]\n",
    "                print(f\"  ‚Üí {round(img_area / page_area * 100, 2)}% of page\")\n",
    "\n",
    "        # Filter out tiny logos\n",
    "        large_imgs = [\n",
    "            img for img in imgs\n",
    "            if (img[\"width\"] * img[\"height\"]) / page_area > LOGO_THRESHOLD\n",
    "        ]\n",
    "\n",
    "        # Heuristic: one large image covers most of the page\n",
    "        composite_area = sum(img[\"width\"] * img[\"height\"] for img in imgs if (img[\"width\"] * img[\"height\"]) / page_area > 0.15)\n",
    "\n",
    "        if composite_area / page_area > 0.40:\n",
    "            full_page_diagram = True\n",
    "\n",
    "        if full_page_diagram:\n",
    "            # Render whole page at high res\n",
    "            pix = page.get_pixmap(matrix=fitz.Matrix(PIXMAP_ZOOM, PIXMAP_ZOOM))\n",
    "            f = BASE_DIR / \"page_images\" / f\"diagram_page_{page_idx:03d}.png\"\n",
    "            save_pixmap(pix, f)\n",
    "            caption = caption_image_cached(f)\n",
    "            # If page text is too short, pull context from neighbors\n",
    "            related = \"\"\n",
    "            if len(raw_text) <= TEXT_EMPTY_LIMIT:\n",
    "                for adj_idx in (page_idx - 1, page_idx + 1):\n",
    "                    if 0 <= adj_idx < len(doc):\n",
    "                        adj_text = doc[adj_idx].get_text(\"text\", sort=True).strip()\n",
    "                        if len(adj_text) >= NEIGHBOR_MIN_CHARS:\n",
    "                            related += f\"\\n[[Neighbor page {adj_idx}]]\\n\" + adj_text\n",
    "            items.append({\n",
    "            \"page\": page_idx,\n",
    "            \"type\": \"page\",\n",
    "            \"path\": str(f),\n",
    "            \"text\": caption,          # the GPT-4o caption\n",
    "            \"related_text\": related.strip()  # may be empty if nothing useful\n",
    "            })\n",
    "            print(f\"‚úÖ Detected composite diagram on page {page_idx} covering {round(composite_area / page_area * 100, 2)}%\")\n",
    "\n",
    "            m = re.search(r\"(Figure\\s+\\d+\\s*[\\‚Äì\\-‚Äî]\\s*[^\\n]{5,80})\", raw_text)\n",
    "            if m:\n",
    "                items[-1][\"caption_title\"] = m.group(1).strip()\n",
    "\n",
    "        else:\n",
    "            # Normal inline images\n",
    "            page_area = page.rect.width * page.rect.height\n",
    "\n",
    "            with pdfplumber.open(pdf_path) as plumber_pdf:\n",
    "                plumber_page = plumber_pdf.pages[page_idx]\n",
    "                imgs = plumber_page.images  # contains width, height, x0, y0, etc.\n",
    "\n",
    "            for idx, img in enumerate(page.get_images(full=True)):\n",
    "                xref = img[0]\n",
    "\n",
    "                # üîç Find the matching image in plumber by xref (or fallback to estimated area)\n",
    "                matching = next((i for i in imgs if i.get(\"name\") == img[7]), None)\n",
    "\n",
    "                if matching:\n",
    "                    img_area = matching[\"width\"] * matching[\"height\"]\n",
    "                else:\n",
    "                    pix = fitz.Pixmap(doc, xref)\n",
    "                    img_area = pix.width * pix.height\n",
    "\n",
    "                percent = img_area / page_area\n",
    "\n",
    "                if percent < 0.01:\n",
    "                    print(f\"üóëÔ∏è Skipped small image on page {page_idx}: {round(percent * 100, 2)}% of page\")\n",
    "                    continue\n",
    "\n",
    "                pix = fitz.Pixmap(doc, xref)\n",
    "                fname = BASE_DIR / \"images\" / f\"{pdf_path.stem}_img_{page_idx}_{idx}_{xref}.png\"\n",
    "                save_pixmap(pix, fname)\n",
    "\n",
    "                items.append({\n",
    "                    \"page\": page_idx,\n",
    "                    \"type\": \"image\",\n",
    "                    \"path\": str(fname),\n",
    "                    \"text\": caption_image_cached(fname)\n",
    "                })\n",
    "\n",
    "                m = re.search(r\"(Figure\\s+\\d+\\s*[\\‚Äì\\-‚Äî]\\s*[^\\n]{5,80})\", raw_text)\n",
    "                if m:\n",
    "                    items[-1][\"caption_title\"] = m.group(1).strip()\n",
    "\n",
    "    print(\"\\nüßæ Pages with full-page diagrams:\")\n",
    "    print([item[\"page\"] for item in items if item[\"type\"] == \"page\"])\n",
    "    \n",
    "\n",
    "\n",
    "    print(f\"‚úÖ finished ‚Äì extracted {len(items)} items\")\n",
    "    return items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree(\"data/images\", ignore_errors=True)\n",
    "shutil.rmtree(\"data/page_images\", ignore_errors=True)\n",
    "shutil.rmtree(\"data/tables\", ignore_errors=True)\n",
    "shutil.rmtree(\"data/text\", ignore_errors=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------- RUN ----------------\n",
    "items = extract_pdf(PDF_PATH)\n",
    "\n",
    "# quick sanity prints\n",
    "first_text  = next(i for i in items if i[\"type\"] == \"text\")\n",
    "first_image = next(i for i in items if i[\"type\"] == \"image\" or i[\"type\"] == \"page\")\n",
    "print(\"\\n[Sample text]\", first_text[\"text\"][:200])\n",
    "print(\"[Sample image]\", first_image[\"path\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade openai tqdm  pillow  # pillow only for quick mime-type sniffing\n",
    "from pathlib import Path\n",
    "import base64, mimetypes, uuid, os, time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import openai                     # v1.14+\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from pinecone import Pinecone\n",
    "\n",
    "openai.api_key      = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY    = os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "# ‚îÄ‚îÄ embedding & chat models (adjust if your account differs) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "EMBED_MODEL = \"text-embedding-3-large\"    # 1536-D, GPT-4 family\n",
    "CHAT_MODEL  = \"gpt-4o-mini\"               # vision-capable\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=EMBED_MODEL)\n",
    "\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")  # keep this\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index_name = \"multimodal-manual\"\n",
    "\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,  # or embeddings.embedding_dimension\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "\n",
    "index = pc.Index(index_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_data_uri(path: Path) -> str:\n",
    "    mime, _ = mimetypes.guess_type(path)\n",
    "    b64 = base64.b64encode(path.read_bytes()).decode()\n",
    "    return f\"data:{mime or 'image/png'};base64,{b64}\"\n",
    "\n",
    "def caption_image(path: Path, retry: int = 3) -> str:\n",
    "    \"\"\"Return a single-sentence literal caption for the image.\"\"\"\n",
    "    data_uri = img_to_data_uri(path)\n",
    "    for attempt in range(retry):\n",
    "        try:\n",
    "            resp = openai.chat.completions.create(\n",
    "                model=CHAT_MODEL,\n",
    "                messages=[{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\",\n",
    "                         \"text\": \"Describe this image in one concise sentence, no interpretation.\"},\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\"url\": data_uri}}\n",
    "                    ]\n",
    "                }],\n",
    "                max_tokens=60\n",
    "            )\n",
    "            return resp.choices[0].message.content.strip()\n",
    "        except openai.RateLimitError:\n",
    "            wait = 2 ** attempt\n",
    "            print(f\"rate-limited, retrying in {wait}s\"); time.sleep(wait)\n",
    "    return \"unavailable caption\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "caption_cache_file = \"captions_cache.json\"\n",
    "caption_cache = {}\n",
    "\n",
    "# Load existing cache if present\n",
    "if Path(caption_cache_file).exists():\n",
    "    caption_cache = json.loads(Path(caption_cache_file).read_text())\n",
    "\n",
    "def caption_image_cached(path: Path) -> str:\n",
    "    key = str(path)\n",
    "    if key in caption_cache:\n",
    "        return caption_cache[key]\n",
    "    caption = caption_image(path)  # your existing GPT-4 captioner\n",
    "    caption_cache[key] = caption\n",
    "    Path(caption_cache_file).write_text(json.dumps(caption_cache, indent=2))\n",
    "    return caption\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing docs + metadata: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 600/600 [00:07<00:00, 81.34it/s] \n"
     ]
    }
   ],
   "source": [
    "docs, meta, ids = [], [], []\n",
    "\n",
    "# üßæ Build a quick index of text chunks by page\n",
    "text_by_page = {\n",
    "    obj[\"page\"]: obj[\"text\"].strip()\n",
    "    for obj in items if obj[\"type\"] == \"text\" and obj[\"text\"].strip()\n",
    "}\n",
    "\n",
    "# Prepare logs for captions and skipped pages\n",
    "captioned_pages = []\n",
    "skipped_pages = []\n",
    "\n",
    "for obj in tqdm(items, desc=\"Preparing docs + metadata\"):\n",
    "    # ---------------- TEXT & SECTION ----------------\n",
    "    if obj[\"type\"] == \"text\":\n",
    "        section  = obj.get(\"section\", \"\").strip()\n",
    "        chunk    = tag_special_chunks(obj[\"text\"])\n",
    "        text_repr = f\"[SECTION] {section}\\n{chunk}\" if section else chunk\n",
    "\n",
    "        keywords = [tok.lemma_ for tok in nlp(text_repr)\n",
    "                    if tok.pos_ in {\"NOUN\",\"PROPN\"}]\n",
    "\n",
    "        docs.append(text_repr)\n",
    "        meta.append({**obj, \"keywords\": keywords})\n",
    "        ids.append(str(uuid.uuid4()))\n",
    "\n",
    "    # ---------------- TABLE  (row-level) ------------\n",
    "    elif obj[\"type\"] == \"table\":\n",
    "        rows = obj[\"text\"].splitlines()\n",
    "        if not rows:\n",
    "            continue\n",
    "\n",
    "        # Try to parse header row from first line\n",
    "        header_fields = [col.strip() for col in rows[0].split(\" | \")]\n",
    "\n",
    "        for row in rows[1:]:\n",
    "            cells = [col.strip() for col in row.split(\" | \")]\n",
    "            if not any(cells):\n",
    "                continue\n",
    "\n",
    "            # Align columns if possible\n",
    "            if len(cells) == len(header_fields):\n",
    "                structured = \" | \".join(f\"{h}: {v}\" for h, v in zip(header_fields, cells))\n",
    "            else:\n",
    "                structured = row  # fallback to raw\n",
    "\n",
    "            text_repr = f\"[TABLE ROW] {structured}\"\n",
    "\n",
    "            # optional: extract keywords for filtering\n",
    "            keywords = [tok.lemma_ for tok in nlp(text_repr) if tok.pos_ in {\"NOUN\", \"PROPN\"}]\n",
    "\n",
    "            docs.append(text_repr)\n",
    "            meta.append({**obj, \"keywords\": keywords})\n",
    "            ids.append(str(uuid.uuid4()))\n",
    "\n",
    "\n",
    "    # ---------------- IMAGE & PAGE ------------------\n",
    "    elif obj[\"type\"] in {\"image\", \"page\"}:\n",
    "        caption  = obj.get(\"caption\") or obj.get(\"caption_title\",\"\")\n",
    "        related  = obj.get(\"related_text\",\"\").strip()\n",
    "        prefix   = \"[PAGE IMAGE]\" if obj[\"type\"]==\"page\" else \"[IMAGE]\"\n",
    "        text_repr = f\"{prefix} {caption}\\n{related}\" if related else f\"{prefix} {caption}\"\n",
    "\n",
    "        keywords = [tok.lemma_ for tok in nlp(text_repr)\n",
    "                    if tok.pos_ in {\"NOUN\",\"PROPN\"}]\n",
    "\n",
    "        docs.append(text_repr)\n",
    "        meta.append({**obj, \"keywords\": keywords})\n",
    "        ids.append(str(uuid.uuid4()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total page-image items: 13\n",
      "Pages with captions: []\n"
     ]
    }
   ],
   "source": [
    "# 1. How many 'page' items do we have at all?\n",
    "page_items = [obj for obj in items if obj[\"type\"] == \"page\"]\n",
    "print(\"Total page-image items:\", len(page_items))\n",
    "\n",
    "# 2. Which of them have a non-empty caption?\n",
    "captioned = [\n",
    "    obj for obj in page_items\n",
    "    if obj[\"text\"].strip() and \"[PAGE IMAGE]\" in obj[\"text\"] and \"unavailable caption\" not in obj[\"text\"]\n",
    "]\n",
    "print(\"Pages with captions:\", [obj[\"page\"] for obj in captioned])\n",
    "\n",
    "# 3. Peek at one caption\n",
    "if captioned:\n",
    "    sample = captioned[0]\n",
    "    print(f\"\\nPage {sample['page']} caption ‚Üí\", sample[\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:14<00:00,  1.56s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ‚îÄ‚îÄ embed in batches ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "batch = 100\n",
    "vectors = []\n",
    "for i in tqdm(range(0, len(docs), batch), desc=\"Embedding\"):\n",
    "    vecs = embeddings.embed_documents(docs[i:i+batch])\n",
    "    vectors.extend(vecs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_upsert = [\n",
    "    (\n",
    "        ids[i],\n",
    "        vectors[i],\n",
    "        {**meta[i], \"text\": docs[i]}          # ensure \"text\" key exists\n",
    "    )\n",
    "    for i in range(len(docs))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì§  Upserting to Pinecone ‚Ä¶\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 894/894 [00:54<00:00, 16.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ  Done!  Pinecone now holds:\n",
      "   ‚Ä¢ vectors : 1499\n",
      "   ‚Ä¢ dim      : 3072\n"
     ]
    }
   ],
   "source": [
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "index = pc.Index(\"multimodal-manual\")          # ‚Üê already created with dim=3072\n",
    "\n",
    "def payload_size(batch):\n",
    "    return len(json.dumps(batch).encode())\n",
    "\n",
    "MAX_PAYLOAD = 3_000_000        # ‚âà3 MB (well under 4 MB limit)\n",
    "batch = []\n",
    "\n",
    "print(\"üì§  Upserting to Pinecone ‚Ä¶\")\n",
    "\n",
    "for tup in tqdm(to_upsert):\n",
    "    batch.append(tup)\n",
    "    if payload_size(batch) >= MAX_PAYLOAD:\n",
    "        index.upsert(batch, namespace=\"v1\")\n",
    "        batch = []\n",
    "\n",
    "# any leftovers\n",
    "if batch:\n",
    "    index.upsert(batch, namespace=\"v1\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4 ¬∑ VERIFY\n",
    "# ------------------------------------------------------------\n",
    "stats = index.describe_index_stats(namespace=\"v1\")\n",
    "print(\"\\n‚úÖ  Done!  Pinecone now holds:\")\n",
    "print(f\"   ‚Ä¢ vectors : {stats['namespaces']['v1']['vector_count']}\")\n",
    "print(f\"   ‚Ä¢ dim      : {stats['dimension']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def extract_table_keywords(meta, limit=20):\n",
    "    keyword_counts = Counter()\n",
    "\n",
    "    for m in meta:\n",
    "        if m.get(\"type\") == \"table\":\n",
    "            keyword_counts.update(m.get(\"keywords\", []))\n",
    "\n",
    "    top_keywords = [kw for kw, _ in keyword_counts.most_common(limit)]\n",
    "    return top_keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from IPython.display import display, Image\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Vector store\n",
    "vectorstore = PineconeVectorStore(\n",
    "    index=index,\n",
    "    embedding=embeddings,\n",
    "    namespace=\"v1\",\n",
    "    text_key=\"text\"\n",
    ")\n",
    "\n",
    "# Retriever\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0.2)\n",
    "\n",
    "# Memory\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    "    output_key=\"answer\"  # ‚úÖ Tells memory what to store\n",
    ")\n",
    "\n",
    "# RAG Chain with output key fix\n",
    "chat_rag = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    return_source_documents=True,\n",
    "    output_key=\"answer\"\n",
    ")\n",
    "\n",
    "\n",
    "def ask(query):\n",
    "    def is_table_query(q):\n",
    "        # Add more generic patterns here as needed\n",
    "        table_keywords = extract_table_keywords(meta)\n",
    "        return any(kw in q.lower() for kw in table_keywords)\n",
    "\n",
    "    # 1. Run table-prioritized retrieval if query looks structured\n",
    "    table_mode = is_table_query(query)\n",
    "    if table_mode:\n",
    "        all_docs = retriever.get_relevant_documents(query)\n",
    "        table_docs = [doc for doc in all_docs if doc.metadata.get(\"type\") == \"table\"]\n",
    "        source_docs = table_docs[:5] if table_docs else all_docs[:5]\n",
    "    else:\n",
    "        res = chat_rag.invoke({\"question\": query})\n",
    "        source_docs = res[\"source_documents\"]\n",
    "\n",
    "    # 2. If not using the RAG chain (manual filtered docs), rerun LLM\n",
    "    if \"source_docs\" in locals() and isinstance(source_docs, list) and \"res\" not in locals():\n",
    "        content_blob = \"\\n\\n\".join(doc.page_content for doc in source_docs)\n",
    "        system_prompt = \"You are answering from a technical manual. Prioritize structured information when available, especially from tables.\"\n",
    "        res = llm.invoke([\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"{query}\\n\\nRelevant context:\\n{content_blob}\"}\n",
    "        ])\n",
    "        res = {\"answer\": res.content, \"source_documents\": source_docs}\n",
    "\n",
    "    # 3. Display any image or diagram found\n",
    "    top_image_path = None\n",
    "    top_image_doc  = None\n",
    "    for doc in res[\"source_documents\"]:\n",
    "        doc_type = doc.metadata.get(\"type\")\n",
    "        path     = doc.metadata.get(\"path\")\n",
    "        if doc_type in {\"image\", \"page\"} and Path(path).suffix in {\".png\", \".jpg\", \".jpeg\"}:\n",
    "            top_image_path = path\n",
    "            top_image_doc  = doc\n",
    "            break\n",
    "\n",
    "    if top_image_path:\n",
    "        print(\"\\nüñºÔ∏è  You can refer to the following diagram:\")\n",
    "        print(f\"‚Ä¢ {top_image_doc.metadata.get('type')} ‚Üí {top_image_path} (page {top_image_doc.metadata.get('page')})\")\n",
    "        try:\n",
    "            display(Image(filename=top_image_path, width=400))\n",
    "        except Exception as e:\n",
    "            print(f\"[!] Failed to display image: {e}\")\n",
    "\n",
    "    # 4. Print response and sources\n",
    "    print(f\"\\nüßë: {query}\")\n",
    "    print(f\"ü§ñ: {res['answer']}\")\n",
    "\n",
    "    print(\"\\n--- Sources ---\")\n",
    "    for doc in res[\"source_documents\"]:\n",
    "        print(f\"‚Ä¢ {doc.metadata.get('type')} ‚Üí {doc.metadata.get('path')} (page {doc.metadata.get('page')})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vector = embeddings.embed_query(\"spindle speed\")\n",
    "res = index.query(vector=query_vector, top_k=5, namespace=\"v1\", include_metadata=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üßë: If the lathe is being stored for a long time before commissioning, what are the detailed steps to ensure it's preserved properly, and how should it be prepared again for safe use?\n",
      "ü§ñ: To ensure the lathe is preserved properly during long-term storage, follow these steps:\n",
      "\n",
      "1. Disconnect the power supply cable.\n",
      "2. Protect the machined parts (such as the guides, the carriage, the tool holder slides, spindle, and the tailstock quill) with protective liquid and/or grease.\n",
      "3. Store the lathe in a dry place, free from dust and contaminating agents. The recommended climatic conditions for storage are a temperature range of -15¬∞ to +55¬∞ C and humidity at 95% (non-condensing).\n",
      "4. Make sure the lathe is protected from knocks and vibrations.\n",
      "\n",
      "Before preparing the lathe for safe use after storage, you should:\n",
      "\n",
      "1. Check that all moving parts are well lubricated.\n",
      "2. Clean the surface of the spindle, the turret, and the body of the machine.\n",
      "3. Ensure there are no objects or tools near the moving parts.\n",
      "4. Check the operation of the manually operated handwheels.\n",
      "5. Check the wear of the guide rails.\n",
      "6. Level the lathe rails by placing a level on the sides of the carriage and adjusting the adjustable feet until the bubble remains uniform throughout the entire course of the carriage. This should be checked periodically, at least every six months.\n",
      "7. Lubricate and grease the machine as described in the relevant section on \"Lubrication\" before starting it.\n",
      "\n",
      "These steps will help ensure the lathe is preserved properly during storage and is safe to use once it is commissioned again.\n",
      "\n",
      "--- Sources ---\n",
      "‚Ä¢ text ‚Üí data/text/doc2_text_23_3.txt (page 23.0)\n",
      "‚Ä¢ text ‚Üí data/text/doc2_text_23_3.txt (page 23.0)\n",
      "‚Ä¢ text ‚Üí data/text/doc2_text_50_1.txt (page 50.0)\n",
      "‚Ä¢ text ‚Üí data/text/doc2_text_45_1.txt (page 45.0)\n",
      "‚Ä¢ text ‚Üí data/text/doc2_text_25_2.txt (page 25.0)\n"
     ]
    }
   ],
   "source": [
    "ask(\"If the lathe is being stored for a long time before commissioning, what are the detailed steps to ensure it's preserved properly, and how should it be prepared again for safe use?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üßë: Identify the differences in maintenance schedules between components using Oil and those using Oil 20.\n",
      "ü§ñ: The maintenance schedules for components using Oil versus those using Oil 20 differ primarily in the frequency of lubrication required:\n",
      "\n",
      "1. **Components using Oil 20:**\n",
      "   - **Carriage rails**: Lubricated daily.\n",
      "   - **Gears for threading**: Lubricated every 6 months.\n",
      "   - **Tool carriage**: Lubricated every 6 months.\n",
      "   - **Spindle gears**: Lubricated every 6 months.\n",
      "\n",
      "2. **Components using Oil:**\n",
      "   - **Feed shaft and lead screw bearings**: Lubricated daily.\n",
      "   - **Transverse feed casing**: Lubricated daily.\n",
      "   - **Tailstock sleeve and hand wheel**: Lubricated daily.\n",
      "   - **Transverse slide**: Lubricated daily.\n",
      "   - **Longitudinal slide**: Lubricated daily.\n",
      "   - **Longitudinal feed handwheel**: Lubricated daily.\n",
      "   - **Transverse feed handwheel**: Lubricated daily.\n",
      "\n",
      "In summary, components using Oil require daily lubrication, while those using Oil 20 have a longer maintenance interval, typically every 6 months, except for the carriage rails which require daily lubrication.\n",
      "\n",
      "--- Sources ---\n",
      "‚Ä¢ table ‚Üí data/tables/doc2_table_53_0.txt (page 53.0)\n",
      "‚Ä¢ table ‚Üí data/tables/doc2_table_52_0.txt (page 52.0)\n"
     ]
    }
   ],
   "source": [
    "ask(\"Identify the differences in maintenance schedules between components using Oil and those using Oil 20.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üßë: List all components with a lubrication frequency based on a level indicator, and mention their oil type and replacement frequency.\n",
      "ü§ñ: The components with a lubrication frequency based on a level indicator, along with their oil type and replacement frequency, are:\n",
      "\n",
      "1. Gears for threading\n",
      "   - Oil Type: Oil 20\n",
      "   - Replacement Frequency: 6 months\n",
      "\n",
      "2. Tool carriage\n",
      "   - Oil Type: Oil 20\n",
      "   - Replacement Frequency: 6 months\n",
      "\n",
      "3. Spindle gears\n",
      "   - Oil Type: Oil 20\n",
      "   - Replacement Frequency: 6 months\n",
      "\n",
      "--- Sources ---\n",
      "‚Ä¢ text ‚Üí data/text/doc2_text_53_0.txt (page 53.0)\n",
      "‚Ä¢ table ‚Üí data/tables/doc2_table_52_0.txt (page 52.0)\n",
      "‚Ä¢ text ‚Üí data/text/doc2_text_52_0.txt (page 52.0)\n",
      "‚Ä¢ table ‚Üí data/tables/doc2_table_53_0.txt (page 53.0)\n",
      "‚Ä¢ text ‚Üí data/text/doc2_text_51_1.txt (page 51.0)\n"
     ]
    }
   ],
   "source": [
    "ask(\"List all components with a lubrication frequency based on a level indicator, and mention their oil type and replacement frequency.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def extract_table_keywords(meta, limit=20):\n",
    "    keyword_counts = Counter()\n",
    "\n",
    "    for m in meta:\n",
    "        if m.get(\"type\") == \"table\":\n",
    "            keyword_counts.update(m.get(\"keywords\", []))\n",
    "\n",
    "    top_keywords = [kw for kw, _ in keyword_counts.most_common(limit)]\n",
    "    return top_keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[147], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m table_rows \u001b[38;5;241m=\u001b[39m [doc \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource_documents\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m doc\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m‚úÖ Retrieved table rows:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(table_rows))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m table_rows:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'res' is not defined"
     ]
    }
   ],
   "source": [
    "table_rows = [doc for doc in res[\"source_documents\"] if doc.metadata.get(\"type\") == \"table\"]\n",
    "print(\"\\n‚úÖ Retrieved table rows:\", len(table_rows))\n",
    "for doc in table_rows:\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 3072,\n",
       " 'index_fullness': 0.0,\n",
       " 'metric': 'cosine',\n",
       " 'namespaces': {'v1': {'vector_count': 750}},\n",
       " 'total_vector_count': 750,\n",
       " 'vector_type': 'dense'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats(namespace=\"v1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.6529\n",
      "Type: text\n",
      "Path: data/text/doc2_text_28_2.txt\n",
      "\n",
      "Score: 0.6057\n",
      "Type: text\n",
      "Path: data/text/doc2_text_13_4.txt\n",
      "\n",
      "Score: 0.5967\n",
      "Type: text\n",
      "Path: data/text/doc2_text_28_3.txt\n"
     ]
    }
   ],
   "source": [
    "query = \"How to adjust spindle speed?\"\n",
    "\n",
    "query_embedding = embeddings.embed_query(query)\n",
    "\n",
    "res = index.query(\n",
    "    vector=query_embedding,\n",
    "    top_k=3,\n",
    "    namespace=\"v1\",\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "for match in res['matches']:\n",
    "    print(f\"\\nScore: {match['score']:.4f}\")\n",
    "    print(f\"Type: {match['metadata'].get('type')}\")\n",
    "    print(f\"Path: {match['metadata'].get('path')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_matches = [m for m in res['matches'] if m['metadata'].get('type') == 'image']\n",
    "for img in image_matches:\n",
    "    print(f\"üîç Image: {img['metadata'].get('path')} ‚Üí score: {img['score']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "vectorstore = PineconeVectorStore(\n",
    "    index      = index,          # your Pinecone index from earlier\n",
    "    embedding  = embeddings,     # same OpenAIEmbeddings object\n",
    "    namespace  = \"v1\",           # must match your upsert namespace\n",
    "    text_key   = \"text\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.567\n",
      "Type: text\n",
      "Page: 51.0\n",
      "Path: data/text/doc2_text_51_1.txt\n",
      "Text: ...\n",
      "\n",
      "Score: 0.550\n",
      "Type: text\n",
      "Page: 54.0\n",
      "Path: data/text/doc2_text_54_1.txt\n",
      "Text: ...\n",
      "\n",
      "Score: 0.536\n",
      "Type: text\n",
      "Page: 51.0\n",
      "Path: data/text/doc2_text_51_0.txt\n",
      "Text: ...\n"
     ]
    }
   ],
   "source": [
    "query = \"How to lubricate the spindle?\"\n",
    "query_vector = embeddings.embed_query(query)\n",
    "\n",
    "res = index.query(\n",
    "    vector=query_vector,\n",
    "    top_k=3,\n",
    "    namespace=\"v1\",\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "for match in res['matches']:\n",
    "    print(f\"\\nScore: {match['score']:.3f}\")\n",
    "    print(f\"Type: {match['metadata'].get('type')}\")\n",
    "    print(f\"Page: {match['metadata'].get('page')}\")\n",
    "    print(f\"Path: {match['metadata'].get('path')}\")\n",
    "    print(f\"Text: {match['metadata'].get('text', '')[:150]}...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found document with no `text` key. Skipping.\n",
      "Found document with no `text` key. Skipping.\n",
      "Found document with no `text` key. Skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2799' coro=<caption_image_async() done, defined at /var/folders/3x/zwytj0k10b1_d1jp5zlhvt7w0000gn/T/ipykernel_12320/159809286.py:35> exception=APIConnectionError('Connection error.')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpx/_transports/default.py\", line 377, in handle_async_request\n",
      "    resp = await self._pool.handle_async_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 256, in handle_async_request\n",
      "    raise exc from None\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 236, in handle_async_request\n",
      "    response = await connection.handle_async_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpcore/_async/connection.py\", line 103, in handle_async_request\n",
      "    return await self._connection.handle_async_request(request)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 136, in handle_async_request\n",
      "    raise exc\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 106, in handle_async_request\n",
      "    ) = await self._receive_response_headers(**kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 177, in _receive_response_headers\n",
      "    event = await self._receive_event(timeout=timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 217, in _receive_event\n",
      "    data = await self._network_stream.read(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpcore/_backends/anyio.py\", line 32, in read\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/contextlib.py\", line 155, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ReadError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/openai/_base_client.py\", line 1484, in request\n",
      "    response = await self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpx/_client.py\", line 1674, in send\n",
      "    response = await self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpx/_client.py\", line 1702, in _send_handling_auth\n",
      "    response = await self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpx/_client.py\", line 1739, in _send_handling_redirects\n",
      "    response = await self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpx/_client.py\", line 1776, in _send_single_request\n",
      "    response = await transport.handle_async_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpx/_transports/default.py\", line 376, in handle_async_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/contextlib.py\", line 155, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ReadError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/3x/zwytj0k10b1_d1jp5zlhvt7w0000gn/T/ipykernel_12320/159809286.py\", line 41, in caption_image_async\n",
      "    resp = await openai.AsyncOpenAI().chat.completions.create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 2028, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/openai/_base_client.py\", line 1742, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/openai/_base_client.py\", line 1516, in request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2780' coro=<caption_image_async() done, defined at /var/folders/3x/zwytj0k10b1_d1jp5zlhvt7w0000gn/T/ipykernel_12320/159809286.py:35> exception=APITimeoutError('Request timed out.')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpx/_transports/default.py\", line 377, in handle_async_request\n",
      "    resp = await self._pool.handle_async_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 256, in handle_async_request\n",
      "    raise exc from None\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 236, in handle_async_request\n",
      "    response = await connection.handle_async_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpcore/_async/connection.py\", line 103, in handle_async_request\n",
      "    return await self._connection.handle_async_request(request)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 136, in handle_async_request\n",
      "    raise exc\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 106, in handle_async_request\n",
      "    ) = await self._receive_response_headers(**kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 177, in _receive_response_headers\n",
      "    event = await self._receive_event(timeout=timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 217, in _receive_event\n",
      "    data = await self._network_stream.read(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpcore/_backends/anyio.py\", line 32, in read\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/contextlib.py\", line 155, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ReadTimeout\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/openai/_base_client.py\", line 1484, in request\n",
      "    response = await self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpx/_client.py\", line 1674, in send\n",
      "    response = await self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpx/_client.py\", line 1702, in _send_handling_auth\n",
      "    response = await self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpx/_client.py\", line 1739, in _send_handling_redirects\n",
      "    response = await self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpx/_client.py\", line 1776, in _send_single_request\n",
      "    response = await transport.handle_async_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpx/_transports/default.py\", line 376, in handle_async_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/contextlib.py\", line 155, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ReadTimeout\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/3x/zwytj0k10b1_d1jp5zlhvt7w0000gn/T/ipykernel_12320/159809286.py\", line 41, in caption_image_async\n",
      "    resp = await openai.AsyncOpenAI().chat.completions.create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 2028, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/openai/_base_client.py\", line 1742, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/openai/_base_client.py\", line 1502, in request\n",
      "    raise APITimeoutError(request=request) from err\n",
      "openai.APITimeoutError: Request timed out.\n"
     ]
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "docs = retriever.invoke(\"Where is the lubrication diagram?\")\n",
    "\n",
    "for doc in docs:\n",
    "    print(f\"\\nType: {doc.metadata.get('type')}\")\n",
    "    print(f\"Page: {doc.metadata.get('page')}\")\n",
    "    print(f\"Path: {doc.metadata.get('path')}\")\n",
    "    print(f\"Content preview: {doc.page_content[:200]}...\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
