{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf in /Users/rajeev/anaconda3/lib/python3.11/site-packages (1.25.5)\n",
      "Requirement already satisfied: langchain in /Users/rajeev/anaconda3/lib/python3.11/site-packages (0.3.19)\n",
      "Collecting langchain\n",
      "  Obtaining dependency information for langchain from https://files.pythonhosted.org/packages/ed/5c/5c0be747261e1f8129b875fa3bfea736bc5fe17652f9d5e15ca118571b6f/langchain-0.3.25-py3-none-any.whl.metadata\n",
      "  Downloading langchain-0.3.25-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: openai in /Users/rajeev/anaconda3/lib/python3.11/site-packages (1.75.0)\n",
      "Collecting openai\n",
      "  Obtaining dependency information for openai from https://files.pythonhosted.org/packages/3c/4c/3889bc332a6c743751eb78a4bada5761e50a8a847ff0e46c1bd23ce12362/openai-1.78.1-py3-none-any.whl.metadata\n",
      "  Downloading openai-1.78.1-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pinecone-client\n",
      "  Obtaining dependency information for pinecone-client from https://files.pythonhosted.org/packages/5a/e4/7780cd631dc6dad0172a245e958b41b28a70779594c0790fa08b952aa97f/pinecone_client-6.0.0-py3-none-any.whl.metadata\n",
      "  Downloading pinecone_client-6.0.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: tiktoken in /Users/rajeev/anaconda3/lib/python3.11/site-packages (0.9.0)\n",
      "Requirement already satisfied: python-dotenv in /Users/rajeev/anaconda3/lib/python3.11/site-packages (1.0.1)\n",
      "Collecting python-dotenv\n",
      "  Obtaining dependency information for python-dotenv from https://files.pythonhosted.org/packages/1e/18/98a99ad95133c6a6e2005fe89faedf294a748bd5dc803008059409ac9b1e/python_dotenv-1.1.0-py3-none-any.whl.metadata\n",
      "  Using cached python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.58 (from langchain)\n",
      "  Obtaining dependency information for langchain-core<1.0.0,>=0.3.58 from https://files.pythonhosted.org/packages/30/40/aa440a7cd05f1dab5d7c91a1284eb776c3cf3eb59fa18ed39927650cfa38/langchain_core-0.3.59-py3-none-any.whl.metadata\n",
      "  Downloading langchain_core-0.3.59-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
      "  Obtaining dependency information for langchain-text-splitters<1.0.0,>=0.3.8 from https://files.pythonhosted.org/packages/8b/a3/3696ff2444658053c01b6b7443e761f28bb71217d82bb89137a978c5f66f/langchain_text_splitters-0.3.8-py3-none-any.whl.metadata\n",
      "  Using cached langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from langchain) (0.3.6)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from langchain) (2.11.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from langchain) (2.28.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from pinecone-client) (2024.8.30)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from pinecone-client) (0.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from pinecone-client) (2.8.2)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from pinecone-client) (1.26.16)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from tiktoken) (2022.7.9)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.5.3->pinecone-client) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (2.1)\n",
      "Downloading langchain-0.3.25-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.78.1-py3-none-any.whl (680 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m680.9/680.9 kB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pinecone_client-6.0.0-py3-none-any.whl (6.7 kB)\n",
      "Using cached python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Downloading langchain_core-0.3.59-py3-none-any.whl (437 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m437.7/437.7 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Installing collected packages: python-dotenv, pinecone-client, openai, langchain-core, langchain-text-splitters, langchain\n",
      "  Attempting uninstall: python-dotenv\n",
      "    Found existing installation: python-dotenv 1.0.1\n",
      "    Uninstalling python-dotenv-1.0.1:\n",
      "      Successfully uninstalled python-dotenv-1.0.1\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.75.0\n",
      "    Uninstalling openai-1.75.0:\n",
      "      Successfully uninstalled openai-1.75.0\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.55\n",
      "    Uninstalling langchain-core-0.3.55:\n",
      "      Successfully uninstalled langchain-core-0.3.55\n",
      "  Attempting uninstall: langchain-text-splitters\n",
      "    Found existing installation: langchain-text-splitters 0.3.6\n",
      "    Uninstalling langchain-text-splitters-0.3.6:\n",
      "      Successfully uninstalled langchain-text-splitters-0.3.6\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.3.19\n",
      "    Uninstalling langchain-0.3.19:\n",
      "      Successfully uninstalled langchain-0.3.19\n",
      "Successfully installed langchain-0.3.25 langchain-core-0.3.59 langchain-text-splitters-0.3.8 openai-1.78.1 pinecone-client-6.0.0 python-dotenv-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pymupdf langchain openai pinecone-client tiktoken python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()                           # expects .env in the repo root\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_ENV     = os.getenv(\"PINECONE_ENV\")  # e.g. \"gcp-starter\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPERATION AND\n",
      "MAINTENANCE MANUAL\n",
      "Bench Lathe\n",
      "Art. T999/230V – T999/230V3A\n",
      "Art. T999/400V - T999/400V3A\n",
      "TRANSLATION OF THE ORIGINAL INSTRUCTIONS\n",
      "fervi.com\n",
      "\n",
      "MACHINES AND\n",
      "ACCESSORIES\n",
      "Page 2 of 84\n",
      "PREFACE\n",
      "Please ensure you have read this manual before operation\n",
      "TRANSLATION OF THE ORIGINAL INSTRUCTIONS\n",
      "It is compulsory to read this instruction manual before starting operation. The guarantee of\n",
      "smooth operation and full performance of the machine is highly dependent on the application\n",
      "of all the instructions contained in this manual.\n",
      "Operator qualifications\n",
      "The workers responsible for the use of this machine must have all the necessary\n",
      "information and instruction and should be given adequate training in relation to safety\n",
      "regarding:\n",
      "a)\n",
      "Conditions of use for the equipment;\n",
      "b)\n",
      "Foreseeable abnormal situations, pursuant to Article 73 of Legislative Decree\n",
      "81/08.\n",
      "We guarantee the Machine complies with the specifications and technical instructions\n",
      "described in the Manual on the date of issuance an\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "def load_pdf(path: Path) -> str:\n",
    "    doc = fitz.open(path)\n",
    "    text = []\n",
    "    for page in doc:\n",
    "        text.append(page.get_text(\"text\"))\n",
    "    return \"\\n\".join(text)\n",
    "\n",
    "raw_text = load_pdf(Path(\"/Users/rajeev/Downloads/doc2.pdf\"))\n",
    "print(raw_text[:1000])   # sanity‑check first 1 000 chars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tabula-py\n",
      "  Obtaining dependency information for tabula-py from https://files.pythonhosted.org/packages/2f/80/10bc6f303054d1a06eb8628f90e5997f4b1272956a477230f3fa95637c28/tabula_py-2.10.0-py3-none-any.whl.metadata\n",
      "  Downloading tabula_py-2.10.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting jpype1\n",
      "  Obtaining dependency information for jpype1 from https://files.pythonhosted.org/packages/35/a0/638186a75026a02286041e4a0449b1dff799a3914dc1c0716ef9b9367b73/jpype1-1.5.2-cp311-cp311-macosx_10_9_universal2.whl.metadata\n",
      "  Downloading jpype1-1.5.2-cp311-cp311-macosx_10_9_universal2.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: pandas>=0.25.3 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from tabula-py) (1.5.3)\n",
      "Requirement already satisfied: numpy>1.24.4 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from tabula-py) (1.26.4)\n",
      "Requirement already satisfied: distro in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from tabula-py) (1.9.0)\n",
      "Requirement already satisfied: packaging in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from jpype1) (24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from pandas>=0.25.3->tabula-py) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from pandas>=0.25.3->tabula-py) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.1->pandas>=0.25.3->tabula-py) (1.16.0)\n",
      "Downloading tabula_py-2.10.0-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading jpype1-1.5.2-cp311-cp311-macosx_10_9_universal2.whl (584 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m584.5/584.5 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: jpype1, tabula-py\n",
      "Successfully installed jpype1-1.5.2 tabula-py-2.10.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tabula-py jpype1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, base64\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import fitz                         # PyMuPDF 2.0+\n",
    "import tabula                       # needs Java;  pip install tabula-py jpype1\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directories(base_dir: str = \"data\"):\n",
    "    for leaf in [\"images\", \"text\", \"tables\", \"page_images\"]:\n",
    "        os.makedirs(Path(base_dir) / leaf, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tables(filepath: str, doc, page_num: int, base_dir: str, items: list):\n",
    "    \"\"\"Extract all tables on a page with Tabula → save as txt.\"\"\"\n",
    "    try:\n",
    "        tables = tabula.read_pdf(filepath, pages=page_num + 1, multiple_tables=True)\n",
    "        if not tables:\n",
    "            return\n",
    "        for t_idx, df in enumerate(tables):\n",
    "            table_text = \"\\n\".join([\" | \".join(map(str, row)) for row in df.values])\n",
    "            fname = Path(base_dir) / \"tables\" / f\"{Path(filepath).stem}_table_{page_num}_{t_idx}.txt\"\n",
    "            fname.write_text(table_text, encoding=\"utf-8\")\n",
    "            items.append({\"page\": page_num, \"type\": \"table\", \"text\": table_text, \"path\": str(fname)})\n",
    "    except Exception as e:\n",
    "        print(f\"[warn] page {page_num}: table extract failed ➜ {e}\")\n",
    "\n",
    "def process_text_chunks(text: str, splitter, page_num: int, base_dir: str, filepath: str, items: list):\n",
    "    for i, chunk in enumerate(splitter.split_text(text)):\n",
    "        fname = Path(base_dir) / \"text\" / f\"{Path(filepath).stem}_text_{page_num}_{i}.txt\"\n",
    "        fname.write_text(chunk, encoding=\"utf-8\")\n",
    "        items.append({\"page\": page_num, \"type\": \"text\", \"text\": chunk, \"path\": str(fname)})\n",
    "\n",
    "def process_images(doc, page, page_num: int, base_dir: str, filepath: str, items: list):\n",
    "    for idx, img in enumerate(page.get_images(full=True)):\n",
    "        xref = img[0]\n",
    "        pix = fitz.Pixmap(doc, xref)\n",
    "        # handle CMYK → RGB\n",
    "        if pix.alpha or pix.colorspace.n > 3:\n",
    "            pix = fitz.Pixmap(fitz.csRGB, pix)\n",
    "        fname = Path(base_dir) / \"images\" / f\"{Path(filepath).stem}_image_{page_num}_{idx}_{xref}.png\"\n",
    "        pix.save(fname)\n",
    "        items.append({\n",
    "            \"page\": page_num, \"type\": \"image\", \"path\": str(fname),\n",
    "            \"image\": base64.b64encode(fname.read_bytes()).decode(\"utf-8\")\n",
    "        })\n",
    "\n",
    "def process_page_image(page, page_num: int, base_dir: str, items: list):\n",
    "    pix = page.get_pixmap(matrix=fitz.Matrix(2,2))   # 2× for crispness\n",
    "    fname = Path(base_dir) / \"page_images\" / f\"page_{page_num:03d}.png\"\n",
    "    pix.save(fname)\n",
    "    items.append({\n",
    "        \"page\": page_num, \"type\": \"page\", \"path\": str(fname),\n",
    "        \"image\": base64.b64encode(fname.read_bytes()).decode(\"utf-8\")\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDF pages: 100%|██████████| 84/84 [00:30<00:00,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  finished – extracted 750 items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "filepath = \"/Users/rajeev/Downloads/doc2.pdf\"          # ← update if needed\n",
    "base_dir = \"data\"              # root output folder\n",
    "\n",
    "create_directories(base_dir)\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=700, chunk_overlap=200, length_function=len\n",
    ")\n",
    "\n",
    "items = []\n",
    "\n",
    "doc = fitz.open(filepath)\n",
    "for page_num in tqdm(range(len(doc)), desc=\"Processing PDF pages\"):\n",
    "    page = doc[page_num]\n",
    "    text = page.get_text(\"text\")\n",
    "\n",
    "    process_tables(filepath, doc, page_num, base_dir, items)\n",
    "    process_text_chunks(text, splitter, page_num, base_dir, filepath, items)\n",
    "    process_images(doc, page, page_num, base_dir, filepath, items)\n",
    "    process_page_image(page, page_num, base_dir, items)\n",
    "\n",
    "print(f\"✅  finished – extracted {len(items)} items\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPERATION AND\n",
      "MAINTENANCE MANUAL\n",
      "Bench Lathe\n",
      "Art. T999/230V – T999/230V3A\n",
      "Art. T999/400V - T999/400V3A\n",
      "TRANSLATION OF THE ORIGINAL INSTRUCTIONS\n",
      "fervi.com\n",
      "2.2 | Safety rules for electrical machine equipment ..............................................................9\n",
      "2.3 | Technical Assistance .........................................................\n",
      "data/images/doc2_image_0_0_515.png\n"
     ]
    }
   ],
   "source": [
    "# First text chunk – preview 200 chars\n",
    "first_text = next(obj for obj in items if obj[\"type\"] == \"text\")\n",
    "print(first_text[\"text\"][:200])\n",
    "\n",
    "# First table – preview 200 chars\n",
    "first_table = next(obj for obj in items if obj[\"type\"] == \"table\")\n",
    "print(first_table[\"text\"][:200])\n",
    "\n",
    "# First image – show path (or the base64 string length, etc.)\n",
    "first_img = next(obj for obj in items if obj[\"type\"] == \"image\")\n",
    "print(first_img[\"path\"])\n",
    "# print(len(first_img[\"image\"]))   # if you want to confirm it’s base64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/rajeev/anaconda3/lib/python3.11/site-packages (1.78.1)\n",
      "Requirement already satisfied: tqdm in /Users/rajeev/anaconda3/lib/python3.11/site-packages (4.67.1)\n",
      "Requirement already satisfied: pillow in /Users/rajeev/anaconda3/lib/python3.11/site-packages (11.2.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from openai) (2.11.3)\n",
      "Requirement already satisfied: sniffio in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade openai tqdm  pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping pinecone-client as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: pinecone 6.0.2\n",
      "Uninstalling pinecone-6.0.2:\n",
      "  Successfully uninstalled pinecone-6.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall pinecone-client pinecone -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pinecone\n",
      "  Obtaining dependency information for pinecone from https://files.pythonhosted.org/packages/5b/c7/2bc1210aa51528b9ba75aede1f169998f50942cc47cdd82dd2dbcba4faa5/pinecone-6.0.2-py3-none-any.whl.metadata\n",
      "  Using cached pinecone-6.0.2-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from pinecone) (2024.8.30)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from pinecone) (0.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from pinecone) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from pinecone) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from pinecone) (1.26.16)\n",
      "Requirement already satisfied: six>=1.5 in /Users/rajeev/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.5.3->pinecone) (1.16.0)\n",
      "Using cached pinecone-6.0.2-py3-none-any.whl (421 kB)\n",
      "Installing collected packages: pinecone\n",
      "Successfully installed pinecone-6.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pinecone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: pinecone\n",
      "Version: 6.0.2\n",
      "Summary: Pinecone client and SDK\n",
      "Home-page: \n",
      "Author: Pinecone Systems, Inc.\n",
      "Author-email: support@pinecone.io\n",
      "License: Apache-2.0\n",
      "Location: /Users/rajeev/anaconda3/lib/python3.11/site-packages\n",
      "Requires: certifi, pinecone-plugin-interface, python-dateutil, typing-extensions, urllib3\n",
      "Required-by: langchain-pinecone\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show pinecone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probably not needed\n",
    "\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "index_name = \"multimodal-manual\"\n",
    "\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,  # for `text-embedding-4-small`\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",          # or \"gcp\"\n",
    "            region=\"us-east-1\"    # or any supported region\n",
    "        )\n",
    "    )\n",
    "\n",
    "index = pc.Index(index_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade openai tqdm  pillow  # pillow only for quick mime-type sniffing\n",
    "from pathlib import Path\n",
    "import base64, mimetypes, uuid, os, time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import openai                     # v1.14+\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import pinecone\n",
    "\n",
    "openai.api_key      = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY    = os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "# ── embedding & chat models (adjust if your account differs) ────────────\n",
    "EMBED_MODEL = \"text-embedding-3-large\"    # 1536-D, GPT-4 family\n",
    "CHAT_MODEL  = \"gpt-4o-mini\"               # vision-capable\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=EMBED_MODEL)\n",
    "\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")  # keep this\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index_name = \"multimodal-manual\"\n",
    "\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,  # or embeddings.embedding_dimension\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "\n",
    "index = pc.Index(index_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_data_uri(path: Path) -> str:\n",
    "    mime, _ = mimetypes.guess_type(path)\n",
    "    b64 = base64.b64encode(path.read_bytes()).decode()\n",
    "    return f\"data:{mime or 'image/png'};base64,{b64}\"\n",
    "\n",
    "def caption_image(path: Path, retry: int = 3) -> str:\n",
    "    \"\"\"Return a single-sentence literal caption for the image.\"\"\"\n",
    "    data_uri = img_to_data_uri(path)\n",
    "    for attempt in range(retry):\n",
    "        try:\n",
    "            resp = openai.chat.completions.create(\n",
    "                model=CHAT_MODEL,\n",
    "                messages=[{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\",\n",
    "                         \"text\": \"Describe this image in one concise sentence, no interpretation.\"},\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\"url\": data_uri}}\n",
    "                    ]\n",
    "                }],\n",
    "                max_tokens=60\n",
    "            )\n",
    "            return resp.choices[0].message.content.strip()\n",
    "        except openai.RateLimitError:\n",
    "            wait = 2 ** attempt\n",
    "            print(f\"rate-limited, retrying in {wait}s\"); time.sleep(wait)\n",
    "    return \"unavailable caption\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs, meta, ids = [], [], []\n",
    "\n",
    "for obj in tqdm(items, desc=\"Preparing docs\"):          # ← items list from extractor\n",
    "    if obj[\"type\"] in {\"text\", \"table\"}:\n",
    "        text_repr = obj[\"text\"]\n",
    "\n",
    "    elif obj[\"type\"] in {\"image\", \"page\"}:\n",
    "        caption = caption_image(Path(obj[\"path\"]))\n",
    "        text_repr = f\"[IMAGE] {caption}\"\n",
    "        obj[\"caption\"] = caption                      # keep for traceability\n",
    "\n",
    "    else:\n",
    "        continue                                      # skip unknown types\n",
    "\n",
    "    uid = str(uuid.uuid4())\n",
    "    ids.append(uid)\n",
    "    docs.append(text_repr)\n",
    "    meta.append({\"type\": obj[\"type\"],\n",
    "                 \"page\": obj[\"page\"],\n",
    "                 \"path\": obj[\"path\"]})\n",
    "\n",
    "# ── embed in batches ───────────────────────────────────────────\n",
    "batch = 100\n",
    "vectors = []\n",
    "for i in tqdm(range(0, len(docs), batch), desc=\"Embedding\"):\n",
    "    vecs = embeddings.embed_documents(docs[i:i+batch])\n",
    "    vectors.extend(vecs)\n",
    "\n",
    "# ── upsert to Pinecone ────────────────────────────────────────\n",
    "to_upsert = [(ids[i], vectors[i], meta[i]) for i in range(len(ids))]\n",
    "index.upsert(vectors=to_upsert, namespace=\"v1\")\n",
    "\n",
    "print(f\"✅  Upserted {len(to_upsert)} multimodal items to namespace 'v1'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "\n",
    "# 🔁 Delete the old 1536-D index\n",
    "pc.delete_index(\"multimodal-manual\")\n",
    "\n",
    "# 🆕 Create a 3072-D index to match text-embedding-3-large\n",
    "pc.create_index(\n",
    "    name=\"multimodal-manual\",\n",
    "    dimension=3072,\n",
    "    metric=\"cosine\",\n",
    "    spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    ")\n",
    "\n",
    "# 🔗 Then connect to it\n",
    "index = pc.Index(\"multimodal-manual\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Resuming safe batch upsert...\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "\n",
    "def get_payload_size(batch):\n",
    "    return len(json.dumps(batch).encode(\"utf-8\"))\n",
    "\n",
    "MAX_PAYLOAD = 3_500_000\n",
    "batch = []\n",
    "\n",
    "print(\"🔄 Resuming safe batch upsert...\")\n",
    "\n",
    "for vec in to_upsert:\n",
    "    batch.append(vec)\n",
    "    if get_payload_size(batch) >= MAX_PAYLOAD:\n",
    "        index.upsert(batch, namespace=\"v1\")\n",
    "        print(f\"✅ Upserted batch of {len(batch)} items (approx {get_payload_size(batch)//1024} KB)\")\n",
    "        batch = []\n",
    "\n",
    "# Final leftovers\n",
    "if batch:\n",
    "    index.upsert(batch, namespace=\"v1\")\n",
    "    print(f\"✅ Upserted final batch of {len(batch)} items (approx {get_payload_size(batch)//1024} KB)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final leftovers\n",
    "if batch:\n",
    "    index.upsert(batch, namespace=\"v1\")\n",
    "    print(f\"✅ Upserted final batch of {len(batch)} items (approx {get_payload_size(batch)//1024} KB)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REBUILD to_upsert cleanly with proper metadata\n",
    "to_upsert = [\n",
    "    (ids[i], vectors[i], {**meta[i], \"text\": docs[i]})\n",
    "    for i in range(len(docs))\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 3072,\n",
       " 'index_fullness': 0.0,\n",
       " 'metric': 'cosine',\n",
       " 'namespaces': {'v1': {'vector_count': 750}},\n",
       " 'total_vector_count': 750,\n",
       " 'vector_type': 'dense'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats(namespace=\"v1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.6529\n",
      "Type: text\n",
      "Path: data/text/doc2_text_28_2.txt\n",
      "\n",
      "Score: 0.6057\n",
      "Type: text\n",
      "Path: data/text/doc2_text_13_4.txt\n",
      "\n",
      "Score: 0.5967\n",
      "Type: text\n",
      "Path: data/text/doc2_text_28_3.txt\n"
     ]
    }
   ],
   "source": [
    "query = \"How to adjust spindle speed?\"\n",
    "\n",
    "query_embedding = embeddings.embed_query(query)\n",
    "\n",
    "res = index.query(\n",
    "    vector=query_embedding,\n",
    "    top_k=3,\n",
    "    namespace=\"v1\",\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "for match in res['matches']:\n",
    "    print(f\"\\nScore: {match['score']:.4f}\")\n",
    "    print(f\"Type: {match['metadata'].get('type')}\")\n",
    "    print(f\"Path: {match['metadata'].get('path')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_matches = [m for m in res['matches'] if m['metadata'].get('type') == 'image']\n",
    "for img in image_matches:\n",
    "    print(f\"🔍 Image: {img['metadata'].get('path')} → score: {img['score']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "vectorstore = PineconeVectorStore(\n",
    "    index      = index,          # your Pinecone index from earlier\n",
    "    embedding  = embeddings,     # same OpenAIEmbeddings object\n",
    "    namespace  = \"v1\",           # must match your upsert namespace\n",
    "    text_key   = \"text\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.567\n",
      "Type: text\n",
      "Page: 51.0\n",
      "Path: data/text/doc2_text_51_1.txt\n",
      "Text: ...\n",
      "\n",
      "Score: 0.550\n",
      "Type: text\n",
      "Page: 54.0\n",
      "Path: data/text/doc2_text_54_1.txt\n",
      "Text: ...\n",
      "\n",
      "Score: 0.536\n",
      "Type: text\n",
      "Page: 51.0\n",
      "Path: data/text/doc2_text_51_0.txt\n",
      "Text: ...\n"
     ]
    }
   ],
   "source": [
    "query = \"How to lubricate the spindle?\"\n",
    "query_vector = embeddings.embed_query(query)\n",
    "\n",
    "res = index.query(\n",
    "    vector=query_vector,\n",
    "    top_k=3,\n",
    "    namespace=\"v1\",\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "for match in res['matches']:\n",
    "    print(f\"\\nScore: {match['score']:.3f}\")\n",
    "    print(f\"Type: {match['metadata'].get('type')}\")\n",
    "    print(f\"Page: {match['metadata'].get('page')}\")\n",
    "    print(f\"Path: {match['metadata'].get('path')}\")\n",
    "    print(f\"Text: {match['metadata'].get('text', '')[:150]}...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found document with no `text` key. Skipping.\n",
      "Found document with no `text` key. Skipping.\n",
      "Found document with no `text` key. Skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2799' coro=<caption_image_async() done, defined at /var/folders/3x/zwytj0k10b1_d1jp5zlhvt7w0000gn/T/ipykernel_12320/159809286.py:35> exception=APIConnectionError('Connection error.')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpx/_transports/default.py\", line 377, in handle_async_request\n",
      "    resp = await self._pool.handle_async_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 256, in handle_async_request\n",
      "    raise exc from None\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 236, in handle_async_request\n",
      "    response = await connection.handle_async_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpcore/_async/connection.py\", line 103, in handle_async_request\n",
      "    return await self._connection.handle_async_request(request)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 136, in handle_async_request\n",
      "    raise exc\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 106, in handle_async_request\n",
      "    ) = await self._receive_response_headers(**kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 177, in _receive_response_headers\n",
      "    event = await self._receive_event(timeout=timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 217, in _receive_event\n",
      "    data = await self._network_stream.read(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpcore/_backends/anyio.py\", line 32, in read\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/contextlib.py\", line 155, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ReadError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/openai/_base_client.py\", line 1484, in request\n",
      "    response = await self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpx/_client.py\", line 1674, in send\n",
      "    response = await self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpx/_client.py\", line 1702, in _send_handling_auth\n",
      "    response = await self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpx/_client.py\", line 1739, in _send_handling_redirects\n",
      "    response = await self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpx/_client.py\", line 1776, in _send_single_request\n",
      "    response = await transport.handle_async_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpx/_transports/default.py\", line 376, in handle_async_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/contextlib.py\", line 155, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ReadError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/3x/zwytj0k10b1_d1jp5zlhvt7w0000gn/T/ipykernel_12320/159809286.py\", line 41, in caption_image_async\n",
      "    resp = await openai.AsyncOpenAI().chat.completions.create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 2028, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/openai/_base_client.py\", line 1742, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/openai/_base_client.py\", line 1516, in request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2780' coro=<caption_image_async() done, defined at /var/folders/3x/zwytj0k10b1_d1jp5zlhvt7w0000gn/T/ipykernel_12320/159809286.py:35> exception=APITimeoutError('Request timed out.')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpx/_transports/default.py\", line 377, in handle_async_request\n",
      "    resp = await self._pool.handle_async_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 256, in handle_async_request\n",
      "    raise exc from None\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 236, in handle_async_request\n",
      "    response = await connection.handle_async_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpcore/_async/connection.py\", line 103, in handle_async_request\n",
      "    return await self._connection.handle_async_request(request)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 136, in handle_async_request\n",
      "    raise exc\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 106, in handle_async_request\n",
      "    ) = await self._receive_response_headers(**kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 177, in _receive_response_headers\n",
      "    event = await self._receive_event(timeout=timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 217, in _receive_event\n",
      "    data = await self._network_stream.read(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpcore/_backends/anyio.py\", line 32, in read\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/contextlib.py\", line 155, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ReadTimeout\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/openai/_base_client.py\", line 1484, in request\n",
      "    response = await self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpx/_client.py\", line 1674, in send\n",
      "    response = await self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpx/_client.py\", line 1702, in _send_handling_auth\n",
      "    response = await self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpx/_client.py\", line 1739, in _send_handling_redirects\n",
      "    response = await self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpx/_client.py\", line 1776, in _send_single_request\n",
      "    response = await transport.handle_async_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpx/_transports/default.py\", line 376, in handle_async_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/contextlib.py\", line 155, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ReadTimeout\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/3x/zwytj0k10b1_d1jp5zlhvt7w0000gn/T/ipykernel_12320/159809286.py\", line 41, in caption_image_async\n",
      "    resp = await openai.AsyncOpenAI().chat.completions.create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 2028, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/openai/_base_client.py\", line 1742, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rajeev/anaconda3/lib/python3.11/site-packages/openai/_base_client.py\", line 1502, in request\n",
      "    raise APITimeoutError(request=request) from err\n",
      "openai.APITimeoutError: Request timed out.\n"
     ]
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "docs = retriever.invoke(\"Where is the lubrication diagram?\")\n",
    "\n",
    "for doc in docs:\n",
    "    print(f\"\\nType: {doc.metadata.get('type')}\")\n",
    "    print(f\"Page: {doc.metadata.get('page')}\")\n",
    "    print(f\"Path: {doc.metadata.get('path')}\")\n",
    "    print(f\"Content preview: {doc.page_content[:200]}...\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
